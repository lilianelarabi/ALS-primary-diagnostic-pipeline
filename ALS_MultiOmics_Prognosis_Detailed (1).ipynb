{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b5f965be",
      "metadata": {
        "id": "b5f965be"
      },
      "source": [
        "\n",
        "# Multi-omics ALS Prognosis — Detailed Colab Notebook\n",
        "\n",
        "**Purpose:** Train a multimodal latent dynamical model on synthetic multi-omics ALS data (transcriptomics, proteomics, epigenomics, genomics) I generated previously. The model learns cross-omic relationships and latent dynamics so that at inference time **only one omic (e.g., RNA)** can be provided and the model will predict molecular progression / prognosis.\n",
        "\n",
        "---\n",
        "\n",
        "## Project overview (for a bioinformatics audience)\n",
        "\n",
        "This project explores how **integrating multiple omics layers** (transcriptomics, proteomics, epigenomics, genomics) can improve understanding and prediction of **disease progression in Amyotrophic Lateral Sclerosis (ALS)**.\n",
        "\n",
        "Instead of focusing on single datasets, the model learns the **molecular relationships between omics layers**, so that even if only one type (e.g. RNA‑seq) is available for a patient, it can infer the likely molecular state across other layers and predict disease progression.\n",
        "\n",
        "### Biological motivation\n",
        "\n",
        "ALS is a complex neurodegenerative disorder involving disruptions across multiple molecular levels — gene expression, protein regulation, DNA methylation, and genetic variation. Traditional analyses often treat each omics type separately, which loses cross-layer information. This project aims to model the **shared latent structure** underlying these layers — effectively learning a “molecular fingerprint” of ALS progression.\n",
        "\n",
        "---\n",
        "\n",
        "This notebook is **self-contained** and uses the synthetic dataset created earlier in this environment (path: `/mnt/data/synthetic_multiomics_als_realgenes`). It is organized and documented so you can upload it to **Google Colab** and run all cells sequentially.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20af141e",
      "metadata": {
        "id": "20af141e"
      },
      "source": [
        "## Setup — install dependencies and import libraries\n",
        "This cell installs required packages (uncomment in Colab) and imports commonly used libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f2ffe49c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2ffe49c",
        "outputId": "f624a2bc-f598-4a27-c656-0c9d0afb15ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy 2.0.2 pandas 2.2.2\n",
            "torch 2.8.0+cu126\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Uncomment the next line when running in Colab\n",
        "# !pip install --quiet torch numpy pandas scikit-learn matplotlib seaborn joblib\n",
        "\n",
        "import os, sys, math, random, json, time\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import joblib\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "print(\"numpy\", np.__version__, \"pandas\", pd.__version__)\n",
        "print(\"torch\", torch.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a166e8b",
      "metadata": {
        "id": "6a166e8b"
      },
      "source": [
        "## Load synthetic multi-omics data\n",
        "We use the synthetic multi-omics dataset generated earlier in this session. Files are expected at `/mnt/data/synthetic_multiomics_als_realgenes`.\n",
        "If you run in Colab, upload the files to the same path or modify the paths accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7bb84640",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "7bb84640",
        "outputId": "d9417d26-a834-4144-ec7a-6c241e17eb53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base_path exists: False\n",
            "/mnt/data/synthetic_multiomics_als_realgenes/rna_counts_samples_x_genes.csv False\n",
            "/mnt/data/synthetic_multiomics_als_realgenes/proteomics_samples_x_proteins.csv False\n",
            "/mnt/data/synthetic_multiomics_als_realgenes/methylation_samples_x_cpgs.csv False\n",
            "/mnt/data/synthetic_multiomics_als_realgenes/genomics_samples_x_variants.csv False\n",
            "/mnt/data/synthetic_multiomics_als_realgenes/sample_metadata.csv False\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/mnt/data/synthetic_multiomics_als_realgenes/rna_counts_samples_x_genes.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3131659792.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Load, using metabolomics if methylation isn't present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mrna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrna_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprot_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethyl_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/synthetic_multiomics_als_realgenes/rna_counts_samples_x_genes.csv'"
          ]
        }
      ],
      "source": [
        "\n",
        "base_path = \"/mnt/data/synthetic_multiomics_als_realgenes\"\n",
        "print(\"base_path exists:\", os.path.exists(base_path))\n",
        "\n",
        "rna_path = os.path.join(base_path, \"rna_counts_samples_x_genes.csv\")\n",
        "prot_path = os.path.join(base_path, \"proteomics_samples_x_proteins.csv\")\n",
        "epi_path = os.path.join(base_path, \"metabolomics_samples_x_metabolites.csv\")  # note: used metabolomics earlier as proxy\n",
        "# In earlier generation methylation file name was 'methylation_samples_x_cpgs.csv' if present, try both\n",
        "methyl_path = os.path.join(base_path, \"methylation_samples_x_cpgs.csv\")\n",
        "geno_path = os.path.join(base_path, \"genomics_samples_x_variants.csv\")\n",
        "meta_path = os.path.join(base_path, \"sample_metadata.csv\")\n",
        "\n",
        "for p in [rna_path, prot_path, methyl_path, geno_path, meta_path]:\n",
        "    print(p, os.path.exists(p))\n",
        "\n",
        "# Load, using metabolomics if methylation isn't present\n",
        "rna = pd.read_csv(rna_path, index_col=0)\n",
        "prot = pd.read_csv(prot_path, index_col=0)\n",
        "if os.path.exists(methyl_path):\n",
        "    epi = pd.read_csv(methyl_path, index_col=0)\n",
        "else:\n",
        "    # fallback to metabolomics file if methylation not found\n",
        "    epi = pd.read_csv(epi_path, index_col=0)\n",
        "geno = pd.read_csv(geno_path, index_col=0)\n",
        "meta = pd.read_csv(meta_path)\n",
        "\n",
        "# Align samples (order)\n",
        "samples = list(rna.index)\n",
        "prot = prot.reindex(samples)\n",
        "epi = epi.reindex(samples)\n",
        "geno = geno.reindex(samples)\n",
        "meta = meta.set_index(\"sample_id\").reindex(samples)\n",
        "\n",
        "print(\"Samples count:\", len(samples))\n",
        "print(\"RNA shape:\", rna.shape, \"Proteomics shape:\", prot.shape, \"Epi shape:\", epi.shape, \"Geno shape:\", geno.shape)\n",
        "meta.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95d77e30",
      "metadata": {
        "id": "95d77e30"
      },
      "source": [
        "## Quick exploratory checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dd8c0e8",
      "metadata": {
        "id": "8dd8c0e8"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"Groups distribution:\\n\", meta['group'].value_counts())\n",
        "print(\"\\nRNA example genes:\", list(rna.columns[:8]))\n",
        "display(rna.iloc[:5, :8])\n",
        "display(prot.iloc[:5, :8])\n",
        "display(epi.iloc[:5, :8])\n",
        "display(geno.iloc[:5, :8])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e827aac5",
      "metadata": {
        "id": "e827aac5"
      },
      "source": [
        "## Preprocessing\n",
        "Normalize each omic appropriately, select top variable features to keep the model compact."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fd86e052",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "fd86e052",
        "outputId": "e0298c28-7b8a-4685-cba1-ff916b5a85fb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'rna' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-752740665.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrna_log2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_log2_cpm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprot_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprot\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# proteomics log scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# epi: if methylation (0-1) convert to M-values; if metabolomics keep log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'rna' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# RNA: log2 CPM\n",
        "def normalize_log2_cpm(df):\n",
        "    mat = df.values.astype(float)\n",
        "    lib = mat.sum(axis=1, keepdims=True)\n",
        "    cpm = (mat / (lib + 1e-9)) * 1e6\n",
        "    return pd.DataFrame(np.log2(cpm + 1.0), index=df.index, columns=df.columns)\n",
        "\n",
        "rna_log2 = normalize_log2_cpm(rna)\n",
        "prot_log = np.log1p(prot)  # proteomics log scale\n",
        "# epi: if methylation (0-1) convert to M-values; if metabolomics keep log\n",
        "if ((epi.values >= 0).all() and (epi.values <= 1).all()):\n",
        "    # treat as methylation beta -> M-values\n",
        "    epi_m = pd.DataFrame(np.log((epi+1e-6) / (1 - epi + 1e-6)), index=epi.index, columns=epi.columns)\n",
        "else:\n",
        "    epi_m = np.log1p(epi)\n",
        "\n",
        "geno_bin = geno.copy()  # assume 0/1\n",
        "\n",
        "# Feature selection: keep top variance features per modality\n",
        "def select_top_var(df, k):\n",
        "    if df.shape[1] <= k:\n",
        "        return df\n",
        "    vars_ = df.var(axis=0)\n",
        "    keep = vars_.sort_values(ascending=False).index[:k]\n",
        "    return df[keep]\n",
        "\n",
        "rna_sel = select_top_var(rna_log2, 800)\n",
        "prot_sel = select_top_var(prot_log, 150)\n",
        "epi_sel = select_top_var(epi_m, 150)\n",
        "geno_sel = geno_bin  # keep all variants (likely small)\n",
        "\n",
        "print(\"Selected shapes:\", rna_sel.shape, prot_sel.shape, epi_sel.shape, geno_sel.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e2de9d9",
      "metadata": {
        "id": "2e2de9d9"
      },
      "source": [
        "## Standardize features and prepare baseline/follow-up\n",
        "We will simulate a follow-up (6 months) by applying a small drift correlated with an artificial progression slope per sample — this mirrors how the previous prototype created longitudinal pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "93a6e292",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "93a6e292",
        "outputId": "d1dcfe9c-631d-45fd-a9ad-83c233c6a34a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'rna_sel' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2707098448.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Fit scalers per modality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mscaler_rna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrna_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mscaler_prot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprot_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mscaler_epi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepi_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'rna_sel' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Fit scalers per modality\n",
        "scaler_rna = StandardScaler().fit(rna_sel.values)\n",
        "scaler_prot = StandardScaler().fit(prot_sel.values)\n",
        "scaler_epi = StandardScaler().fit(epi_sel.values)\n",
        "scaler_geno = StandardScaler().fit(geno_sel.values.astype(float))\n",
        "\n",
        "X_rna = scaler_rna.transform(rna_sel.values)\n",
        "X_prot = scaler_prot.transform(prot_sel.values)\n",
        "X_epi = scaler_epi.transform(epi_sel.values)\n",
        "X_geno = scaler_geno.transform(geno_sel.values.astype(float))\n",
        "\n",
        "N = X_rna.shape[0]\n",
        "groups = list(meta['group'].values)\n",
        "\n",
        "# create synthetic progression slopes (ALS negative)\n",
        "slopes = np.array([ -np.random.uniform(0.2,1.2) if g=='ALS' else np.random.normal(0,0.05) for g in groups ])\n",
        "\n",
        "# function to make followup with small driver changes correlated to slope\n",
        "def make_followup(X, slope, frac_drivers=0.05):\n",
        "    X1 = X.copy()\n",
        "    n_feats = X.shape[1]\n",
        "    n_driver = max(1, int(n_feats * frac_drivers))\n",
        "    for i in range(X.shape[0]):\n",
        "        drivers = np.random.choice(n_feats, size=n_driver, replace=False)\n",
        "        change = (np.sign(-slope[i]) * 0.05 * abs(slope[i]))\n",
        "        X1[i, drivers] += change + np.random.normal(0,0.02, size=n_driver)\n",
        "        X1[i] += np.random.normal(0, 0.01, size=n_feats)\n",
        "    return X1\n",
        "\n",
        "Xr0 = X_rna.copy(); Xr1 = make_followup(Xr0, slopes, frac_drivers=0.03)\n",
        "Xp0 = X_prot.copy(); Xp1 = make_followup(Xp0, slopes, frac_drivers=0.05)\n",
        "Xe0 = X_epi.copy(); Xe1 = make_followup(Xe0, slopes, frac_drivers=0.04)\n",
        "Xg0 = X_geno.copy(); Xg1 = Xg0.copy()  # variants static\n",
        "\n",
        "print(\"Prepared baseline and followup arrays: N=\", N)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c15f7c27",
      "metadata": {
        "id": "c15f7c27"
      },
      "source": [
        "## Model architecture\n",
        "We implement modality-specific encoders and decoders (MLPs), combine posteriors with a Product-of-Experts (PoE) to get a joint `z`, learn linear latent dynamics `z_{t+1} = A z_t + b`, and train a small prognostic head on top of `[z0, dz]`.\n",
        "\n",
        "Details and hyperparameters are commented in the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "51ca390c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "51ca390c",
        "outputId": "ead233b3-81fd-459f-ff0d-3328ffa434ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cpu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Xr0' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1376107036.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m# instantiate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'rna'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mXr0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prot'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mXp0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epi'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mXe0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'geno'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mXg0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0mlatent_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiModalVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Xr0' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# Model components\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"device:\", device)\n",
        "\n",
        "class MLPEncoder(nn.Module):\n",
        "    def __init__(self, in_dim, hidden=[512,256], latent=32):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_dim, hidden[0])\n",
        "        self.fc2 = nn.Linear(hidden[0], hidden[1])\n",
        "        self.mu = nn.Linear(hidden[1], latent)\n",
        "        self.logv = nn.Linear(hidden[1], latent)\n",
        "        self.act = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        h = self.act(self.fc1(x))\n",
        "        h = self.act(self.fc2(h))\n",
        "        return self.mu(h), self.logv(h)\n",
        "\n",
        "class MLPDecoder(nn.Module):\n",
        "    def __init__(self, out_dim, hidden=[256,512], latent=32):\n",
        "        super().__init__()\n",
        "        self.d1 = nn.Linear(latent, hidden[0])\n",
        "        self.d2 = nn.Linear(hidden[0], hidden[1])\n",
        "        self.out = nn.Linear(hidden[1], out_dim)\n",
        "        self.act = nn.ReLU()\n",
        "    def forward(self, z):\n",
        "        h = self.act(self.d1(z))\n",
        "        h = self.act(self.d2(h))\n",
        "        return self.out(h)\n",
        "\n",
        "def poe(mu_list, logvar_list, eps=1e-6):\n",
        "    # Product-of-Experts for Gaussian posteriors\n",
        "    var_list = [torch.exp(lv) + eps for lv in logvar_list]\n",
        "    inv_var = [1.0 / v for v in var_list]\n",
        "    mu = sum(m*iv for m,iv in zip(mu_list, inv_var)) / sum(inv_var)\n",
        "    var = 1.0 / sum(inv_var)\n",
        "    logvar = torch.log(var + eps)\n",
        "    return mu, logvar\n",
        "\n",
        "class MultiModalVAE(nn.Module):\n",
        "    def __init__(self, dims, latent=32):\n",
        "        super().__init__()\n",
        "        # dims: dict with input dims per modality\n",
        "        self.enc_rna = MLPEncoder(dims['rna'], latent=latent)\n",
        "        self.enc_prot = MLPEncoder(dims['prot'], latent=latent)\n",
        "        self.enc_epi = MLPEncoder(dims['epi'], latent=latent)\n",
        "        self.enc_geno = MLPEncoder(dims['geno'], latent=latent)\n",
        "\n",
        "        self.dec_rna = MLPDecoder(dims['rna'], latent=latent)\n",
        "        self.dec_prot = MLPDecoder(dims['prot'], latent=latent)\n",
        "        self.dec_epi = MLPDecoder(dims['epi'], latent=latent)\n",
        "        self.dec_geno = MLPDecoder(dims['geno'], latent=latent)\n",
        "\n",
        "        # linear dynamics layer (learnable A via Linear)\n",
        "        self.dyn = nn.Linear(latent, latent, bias=True)\n",
        "\n",
        "        # prognostic head: maps [z0, z1_pred - z0] -> scalar slope\n",
        "        self.prog = nn.Sequential(nn.Linear(latent*2, latent), nn.ReLU(), nn.Linear(latent,1))\n",
        "\n",
        "        self.latent = latent\n",
        "\n",
        "    def encode_modal(self, x, modality):\n",
        "        if modality=='rna': return self.enc_rna(x)\n",
        "        if modality=='prot': return self.enc_prot(x)\n",
        "        if modality=='epi': return self.enc_epi(x)\n",
        "        if modality=='geno': return self.enc_geno(x)\n",
        "        raise ValueError('Unknown modality')\n",
        "\n",
        "    def decode_modal(self, z, modality):\n",
        "        if modality=='rna': return self.dec_rna(z)\n",
        "        if modality=='prot': return self.dec_prot(z)\n",
        "        if modality=='epi': return self.dec_epi(z)\n",
        "        if modality=='geno': return self.dec_geno(z)\n",
        "        raise ValueError('Unknown modality')\n",
        "\n",
        "    def sample_z(self, mu, logv):\n",
        "        std = torch.exp(0.5*logv)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # inputs: dict of tensors or None for each modality\n",
        "        mus=[]; logvs=[]\n",
        "        for m in ['rna','prot','epi','geno']:\n",
        "            x = inputs.get(m, None)\n",
        "            if x is not None:\n",
        "                mu, logv = self.encode_modal(x, m)\n",
        "                mus.append(mu); logvs.append(logv)\n",
        "        # joint posterior via PoE\n",
        "        mu_joint, logvar_joint = poe(mus, logvs)\n",
        "        z = self.sample_z(mu_joint, logvar_joint)\n",
        "        # reconstructions for all modalities from joint z\n",
        "        recons = {m: self.decode_modal(z, m) for m in ['rna','prot','epi','geno']}\n",
        "        return recons, mu_joint, logvar_joint, z\n",
        "\n",
        "    def predict_next_z(self, z):\n",
        "        return self.dyn(z)\n",
        "\n",
        "    def prognostic(self, z0, z1_pred):\n",
        "        x = torch.cat([z0, z1_pred - z0], dim=1)\n",
        "        return self.prog(x).squeeze(1)\n",
        "\n",
        "# instantiate model\n",
        "dims = {'rna': Xr0.shape[1], 'prot': Xp0.shape[1], 'epi': Xe0.shape[1], 'geno': Xg0.shape[1]}\n",
        "latent_dim = 32\n",
        "model = MultiModalVAE(dims, latent=latent_dim).to(device)\n",
        "print('Model initialized with latent dim', latent_dim)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6bc9701",
      "metadata": {
        "id": "a6bc9701"
      },
      "source": [
        "## Prepare tensors and helper functions\n",
        "We prepare PyTorch tensors and a small helper to sample minibatches with modality dropout (to teach encoders robustness to missing data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eef27d6",
      "metadata": {
        "id": "6eef27d6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Prepare tensors\n",
        "tensor_r0 = torch.tensor(Xr0, dtype=torch.float32).to(device)\n",
        "tensor_p0 = torch.tensor(Xp0, dtype=torch.float32).to(device)\n",
        "tensor_e0 = torch.tensor(Xe0, dtype=torch.float32).to(device)\n",
        "tensor_g0 = torch.tensor(Xg0, dtype=torch.float32).to(device)\n",
        "\n",
        "tensor_r1 = torch.tensor(Xr1, dtype=torch.float32).to(device)\n",
        "tensor_p1 = torch.tensor(Xp1, dtype=torch.float32).to(device)\n",
        "tensor_e1 = torch.tensor(Xe1, dtype=torch.float32).to(device)\n",
        "tensor_g1 = torch.tensor(Xg1, dtype=torch.float32).to(device)\n",
        "\n",
        "slopes_t = torch.tensor(slopes, dtype=torch.float32).to(device)\n",
        "\n",
        "N = Xr0.shape[0]\n",
        "batch_size = 32\n",
        "\n",
        "def sample_batch(idx_batch, drop_prob=0.25):\n",
        "    inputs0 = {}\n",
        "    for name, t in [('rna', tensor_r0), ('prot', tensor_p0), ('epi', tensor_e0), ('geno', tensor_g0)]:\n",
        "        if np.random.rand() > drop_prob:\n",
        "            inputs0[name] = t[idx_batch]\n",
        "        else:\n",
        "            inputs0[name] = None\n",
        "    inputs1 = {'rna': tensor_r1[idx_batch], 'prot': tensor_p1[idx_batch], 'epi': tensor_e1[idx_batch], 'geno': tensor_g1[idx_batch]}\n",
        "    return inputs0, inputs1, slopes_t[idx_batch]\n",
        "\n",
        "print('Tensors ready. N=', N, 'batch_size=', batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ed7853f",
      "metadata": {
        "id": "4ed7853f"
      },
      "source": [
        "## Pretraining: VAE with cross-reconstruction and latent dynamics\n",
        "We train the multimodal VAE with modality dropout and include a dynamics loss so the latent captures temporal change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "577d2b2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "577d2b2d",
        "outputId": "2d6a7cba-11ad-4183-9775-83dd6018de72"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-839246485.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlambda_cross\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# Training hyperparameters\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "n_epochs = 100\n",
        "beta = 0.1\n",
        "lambda_cross = 1.0\n",
        "gamma_dyn = 1.0\n",
        "\n",
        "model.train()\n",
        "for epoch in range(n_epochs):\n",
        "    perm = np.random.permutation(N)\n",
        "    epoch_loss = 0.0\n",
        "    for i in range(0, N, batch_size):\n",
        "        batch_idx = perm[i:i+batch_size]\n",
        "        inputs0, inputs1, slopes_b = sample_batch(batch_idx, drop_prob=0.25)\n",
        "        recons0, mu0, logv0, z0 = model(inputs0)\n",
        "        # reconstruction loss for modalities present at time0\n",
        "        recon_loss = 0.0\n",
        "        for m in ['rna','prot','epi','geno']:\n",
        "            if inputs0.get(m) is not None:\n",
        "                recon_loss += F.mse_loss(recons0[m], inputs0[m])\n",
        "        # dynamics: get true z1 by encoding full modalities at time1 (no dropout)\n",
        "        mus1=[]; logvs1=[]\n",
        "        for m in ['rna','prot','epi','geno']:\n",
        "            x1 = inputs1[m]\n",
        "            mu1, logv1 = model.encode_modal(x1, m)\n",
        "            mus1.append(mu1); logvs1.append(logv1)\n",
        "        mu1_joint, logv1_joint = poe(mus1, logvs1)\n",
        "        z1_true = model.sample_z(mu1_joint, logv1_joint).detach()\n",
        "        z1_pred = model.predict_next_z(z0)\n",
        "        dyn_loss = F.mse_loss(z1_pred, z1_true)\n",
        "        # KL\n",
        "        kl = -0.5 * torch.mean(1 + logv0 - mu0.pow(2) - logv0.exp())\n",
        "        loss = recon_loss + lambda_cross * recon_loss + beta * kl + gamma_dyn * dyn_loss\n",
        "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    if (epoch+1) % 10 == 0 or epoch==0:\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs} loss {epoch_loss/N:.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbbf75e8",
      "metadata": {
        "id": "dbbf75e8"
      },
      "source": [
        "## Fit linear latent dynamics (Ridge) using encoded means\n",
        "After pretraining, encode every sample's baseline and follow-up using full modalities to obtain `Z0` and `Z1`. Fit a Ridge regression mapping `Z0 -> Z1` as a robust dynamics estimator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "73cc9472",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "73cc9472",
        "outputId": "0d2b5b8d-ca22-4c03-e686-f237b12d6068"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2229466482.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmus0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mlogvs0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmus1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mlogvs1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rna'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_r0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_r1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'prot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_p0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_p1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'epi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_e0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_e1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'geno'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_g0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_g1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    mus0=[]; logvs0=[]\n",
        "    mus1=[]; logvs1=[]\n",
        "    for m, t0, t1 in [('rna', tensor_r0, tensor_r1), ('prot', tensor_p0, tensor_p1), ('epi', tensor_e0, tensor_e1), ('geno', tensor_g0, tensor_g1)]:\n",
        "        mu0_m, logv0_m = model.encode_modal(t0, m)\n",
        "        mu1_m, logv1_m = model.encode_modal(t1, m)\n",
        "        mus0.append(mu0_m); logvs0.append(logv0_m)\n",
        "        mus1.append(mu1_m); logvs1.append(logv1_m)\n",
        "    mu0_joint, logv0_joint = poe(mus0, logvs0)\n",
        "    mu1_joint, logv1_joint = poe(mus1, logvs1)\n",
        "    Z0 = mu0_joint.cpu().numpy()\n",
        "    Z1 = mu1_joint.cpu().numpy()\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "ridge_dyn = Ridge(alpha=1.0).fit(Z0, Z1)\n",
        "Z1_pred = ridge_dyn.predict(Z0)\n",
        "print(\"Latent dynamics MSE:\", mean_squared_error(Z1, Z1_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92f8184f",
      "metadata": {
        "id": "92f8184f"
      },
      "source": [
        "## Train prognostic head and evaluate RNA-only inference\n",
        "We train a simple Ridge regression mapping latent features & predicted latent slope to the clinical progression slope. Then evaluate the model when only RNA is provided at inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e9c1d39",
      "metadata": {
        "id": "4e9c1d39"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train/test split (patient-level)\n",
        "from sklearn.model_selection import train_test_split\n",
        "idx = np.arange(N)\n",
        "train_idx, test_idx = train_test_split(idx, test_size=0.2, random_state=42, stratify=np.array(groups))\n",
        "\n",
        "# Compute RNA-only encoded z0 (means)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    mu_rna0, logv_rna0 = model.encode_modal(torch.tensor(Xr0, dtype=torch.float32).to(device), 'rna')\n",
        "    Z0_rna = mu_rna0.cpu().numpy()\n",
        "\n",
        "# z1 from ridge dyn applied to RNA-only z0\n",
        "Z1_from_rna = ridge_dyn.predict(Z0_rna)\n",
        "Xprog_all = np.hstack([Z0, (Z1 - Z0)])  # full-modal training features\n",
        "# train ridge prognostic on full-modal latent features (simulate availability in training)\n",
        "ridge_prog = Ridge(alpha=1.0).fit(Xprog_all, slopes)\n",
        "\n",
        "# Evaluate RNA-only inference on test set\n",
        "Xprog_rna = np.hstack([Z0_rna, (Z1_from_rna - Z0_rna)])\n",
        "y_pred = ridge_prog.predict(Xprog_rna[test_idx])\n",
        "y_true = slopes[test_idx]\n",
        "print(\"RNA-only prognostic R2:\", r2_score(y_true, y_pred))\n",
        "print(\"MSE:\", mean_squared_error(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43f11515",
      "metadata": {
        "id": "43f11515"
      },
      "source": [
        "## Visualizations & save artifacts\n",
        "PCA of joint latent `Z0` and scatter of true vs predicted progression (RNA-only). Save model and scalers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "08957b57",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "08957b57",
        "outputId": "a06ae459-3065-4879-941a-362b423d3f42"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Z0' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-966690771.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mZ0_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Z0' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(2).fit(Z0)\n",
        "Z0_2 = pca.transform(Z0)\n",
        "plt.figure(figsize=(6,5))\n",
        "for g in np.unique(groups):\n",
        "    mask = np.array(groups) == g\n",
        "    plt.scatter(Z0_2[mask,0], Z0_2[mask,1], label=g, alpha=0.7)\n",
        "plt.legend(); plt.title('Joint latent Z0 PCA'); plt.show()\n",
        "\n",
        "# RNA-only pred vs true\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.scatter(y_true, y_pred, alpha=0.7)\n",
        "plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'k--')\n",
        "plt.xlabel('True slope'); plt.ylabel('Predicted slope'); plt.title('RNA-only prognostic'); plt.show()\n",
        "\n",
        "# Save model + scalers + ridge models\n",
        "out_dir = \"/mnt/data/multiomics_results\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "torch.save(model.state_dict(), os.path.join(out_dir, \"vae_state.pth\"))\n",
        "joblib.dump({'scaler_rna': scaler_rna, 'scaler_prot': scaler_prot, 'scaler_epi': scaler_epi, 'scaler_geno': scaler_geno}, os.path.join(out_dir, \"scalers.pkl\"))\n",
        "joblib.dump({'ridge_dyn': ridge_dyn, 'ridge_prog': ridge_prog}, os.path.join(out_dir, \"models.pkl\"))\n",
        "print(\"Saved artifacts to\", out_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cbffe92",
      "metadata": {
        "id": "4cbffe92"
      },
      "source": [
        "\n",
        "## Conclusion and next steps\n",
        "\n",
        "This notebook demonstrated a full pipeline:\n",
        "- Load synthetic multi-omics ALS data (real gene names).\n",
        "- Preprocess and create baseline/follow-up pairs.\n",
        "- Train a multimodal VAE with cross-reconstruction and latent dynamics.\n",
        "- Fit a robust linear dynamics model in latent space.\n",
        "- Train a prognostic head and evaluate **RNA-only** inference.\n",
        "\n",
        "**Next steps** you may want to run:\n",
        "- Replace synthetic labels with real longitudinal ALSFRS-R or survival data.\n",
        "- Increase sample size and include batch effects for realism.\n",
        "- Replace linear dynamics with latent ODE for irregular sampling.\n",
        "- Add explainability (SHAP) on the prognostic head and pathway enrichment for latent dimensions.\n",
        "\n",
        "If you want, I can now run this entire notebook here and show the outputs (plots, metrics), or package the notebook as a `.ipynb` file for you to download and run in Colab.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}